{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab3.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["F9PmBZql0ow4","7yZYCuVxpngN"],"mount_file_id":"1PD8axMJPIW19SKS0LZUlg-Ps3b7OlikM","authorship_tag":"ABX9TyNkgxdZF3TqAagOjVlEUuPa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g4gyOZKkHDVU"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1PD8axMJPIW19SKS0LZUlg-Ps3b7OlikM#scrollTo=g4gyOZKkHDVU&uniqifier=1)"]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# CUDA setup"]},{"cell_type":"code","metadata":{"id":"p9RIwaPbVQHV"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5YlC1IOTlNb"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV0CidyVeqU"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv2zAXZOu02V"},"source":["%cd /home/grossi/CUDA\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yZYCuVxpngN"},"source":["#VS code on Colab"]},{"cell_type":"markdown","metadata":{"id":"7fRcctBZqHh9"},"source":["How to use [VS Code](https://code.visualstudio.com/) on Google Colab as an editor to write code and run experiments on the Colab VM. With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. \n","\n","\n","---\n","\n","\n","1.  Install the colab-code package using the following command:\n","\n"," ```pip install colabcode```\n","\n","2.  Import `ColabCode` class from the package and launch it:\n","```\n","from colabcode import ColabCode \n","ColabCode()\n","```\n","3. You will get the `ngrok` URL in the output. Click the link and a login page will open in a new tab.\n","\n","> ![alt text](https://drive.google.com/uc?id=1KK8VY85vjZ_WDxWIFaZcn1Znhf6XjSqK)\n","\n","4. You will get access to the VSCode editor interface and can use it to work on CUDA/C++ files\n","> ![alt text](https://drive.google.com/uc?id=1SmMmzAxI_mCg2bcwwRfqN5-dGzg3F9z-)\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DKHvaMw3puK7"},"source":["# 1. Install the colab-code package...\n","!pip install colabcode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIGztaKepvqO"},"source":["# 2. Import and launch...\n","from colabcode import ColabCode\n","ColabCode()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ei_jA0Wkdbq4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5gUDpbz5TZml"},"source":["# Divergence analysis"]},{"cell_type":"code","metadata":{"id":"4GjogJPXwfaY"},"source":["#@title working directory: **divergence**\n","%cd /home/grossi/CUDA/lab3/divergence/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuIBtkKxcFY6"},"source":["%%writefile /home/grossi/CUDA/utils/common.h\n","#include <sys/time.h>\n","\n","#ifndef _COMMON_H\n","#define _COMMON_H\n","\n","#define CHECK(call)                                                            \\\n","{                                                                              \\\n","    const cudaError_t error = call;                                            \\\n","    if (error != cudaSuccess)                                                  \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n","        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n","                cudaGetErrorString(error));                                    \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUBLAS(call)                                                     \\\n","{                                                                              \\\n","    cublasStatus_t err;                                                        \\\n","    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CURAND(call)                                                     \\\n","{                                                                              \\\n","    curandStatus_t err;                                                        \\\n","    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUFFT(call)                                                      \\\n","{                                                                              \\\n","    cufftResult err;                                                           \\\n","    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUSPARSE(call)                                                   \\\n","{                                                                              \\\n","    cusparseStatus_t err;                                                      \\\n","    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n","        cudaError_t cuda_err = cudaGetLastError();                             \\\n","        if (cuda_err != cudaSuccess)                                           \\\n","        {                                                                      \\\n","            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n","                    cudaGetErrorString(cuda_err));                             \\\n","        }                                                                      \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","inline double seconds() {\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","inline void device_name() {\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"device %d: %s\\n\", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","}\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","#endif // _COMMON_H"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlbVvBaXCHBs"},"source":["%%writefile /home/grossi/CUDA/lab3/divergence/div.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <assert.h>\n","#include \"../../utils/common.h\"\n","\n","/*\n"," * Kernel with warp divergence\n"," */\n","__global__ void evenOddDIV(int *c, const ulong N) {\n","\tulong tid = blockIdx.x * blockDim.x + threadIdx.x;\n","\tint a, b;\n","\n","\tif (!(tid % 2))   // branch divergence\n","\t\ta = 2;                  \n","\telse\n","\t\tb = 1;                  \n","\n","\t// check index\n","\tif (tid < N)\n","\t\tc[tid] = a + b;\n","}\n","\n","/*\n"," * Kernel without warp divergence\n"," */\n","__global__ void evenOddNODIV(int *c, const int N) {\n","\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n","\tint a = 0, b = 0;\n","\tunsigned int i, twoWarpSize = 2 * warpSize;\n","\n","\tint wid = tid / warpSize; \t// warp index wid = 0,1,2,3,...\n","\tif (!(wid % 2))\n","\t\ta = 2;                  // branch1: thread tid = 0-31, 64-95, ...\n","\telse\n","\t\tb = 1;                  // branch2: thread tid = 32-63, 96-127, ...\n","\n","\t// right index\n","\tif (!(wid % 2))  // even\n","\t\ti = 2 * (tid % warpSize) + (tid / twoWarpSize) * twoWarpSize;\n","\telse            // odd\n","\t\ti = 2 * (tid % warpSize) + 1 + (tid / twoWarpSize) * twoWarpSize;\n","\n","\t// check index\n","\tif (i < N) {\n","\t\tc[i] = a + b;\n","\t}\n","}\n","\n","/*\n"," * MAIN\n"," */\n","int main(int argc, char **argv) {\n","\n","\t// set up data size\n","\tint blocksize = 1024;\n","\tulong size = 1024*1024;\n","\n","\tif (argc > 1)\n","\t\tblocksize = atoi(argv[1]);\n","\tif (argc > 2)\n","\t\tsize = atoi(argv[2]);\n","\tulong nBytes = size * sizeof(int);\n","\n","\tprintf(\"Data size: %lu  -- \", size);\n","  printf(\"Data size (bytes): %lu MB\\n\", nBytes/1000000);\n","\n","\t// set up execution configuration\n","\tdim3 block(blocksize, 1);\n","\tdim3 grid((size + block.x - 1) / block.x, 1);\n","\tprintf(\"Execution conf (block %d, grid %d)\\nKernels:\\n\", block.x, grid.x);\n","\n","\t// allocate memory\n","\tint *d_C, *C;\n","\tC = (int *) malloc(nBytes);\n","\tCHECK(cudaMalloc((void** )&d_C, nBytes));\n","\n","\t// run kernel 1\n","\tdouble iStart, iElaps;\n","\tiStart = seconds();\n","\tevenOddDIV<<<grid, block>>>(d_C, size);\n","\tCHECK(cudaDeviceSynchronize());\n","\tiElaps = seconds() - iStart;\n","\tprintf(\"\\tevenOddDIV<<<%d, %d>>> elapsed time %f sec \\n\\n\", grid.x, block.x, iElaps);\n","\tCHECK(cudaGetLastError());\n","  \n","  CHECK(cudaMemcpy(C, d_C, nBytes, cudaMemcpyDeviceToHost));\n","\n","\n","\t// run kernel 2\n","  CHECK(cudaMemset(d_C, 0.0, nBytes)); // reset memory\n","\tiStart = seconds();\n","\tevenOddNODIV<<<grid, block>>>(d_C, size);\n","\tiElaps = seconds() - iStart;\n","\tprintf(\"\\tevenOddNODIV<<<%d, %d>>> elapsed time %f sec \\n\\n\", grid.x, block.x, iElaps);\n","\tCHECK(cudaGetLastError());\n","\n","\tCHECK(cudaMemcpy(C, d_C, nBytes, cudaMemcpyDeviceToHost));\n","\n","\tfree(C);\n","\t// free gpu memory and reset device\n","\tCHECK(cudaFree(d_C));\n","\tCHECK(cudaDeviceReset());\n","\treturn EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMEGfjJMcX_e"},"source":["# Compilazione ed esecuzione\n","!nvcc div.cu -o div \n","!div 1024 2000000000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdQqnuH-54Ie"},"source":["# Compilazione ed esecuzione versione di debug \n","!nvcc -g -G div.cu -o div_deb\n","!div_deb 1024 2000000000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ygwWcMU9DJmG"},"source":["#Parallel Reduction"]},{"cell_type":"code","metadata":{"id":"K0bWVYl6NVz3"},"source":["#@title working directory: **parReduce**\n","%cd /home/grossi/CUDA/lab3/parReduce/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WThhkz6GDMsm"},"source":["%%writefile /home/grossi/CUDA/lab3/parReduce/parReduce.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <assert.h>\n","\n","#include \"../../utils/common.h\"\n","\n","/*\n"," *  Block by block parallel implementation with divergence (sequential schema)\n"," */\n","__global__ void blockParReduce1(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n","\t\tif ((tid % (2 * stride)) == 0)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n"," *  Block by block parallel implementation without divergence (interleaved schema)\n"," */\n","__global__ void blockParReduce2(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1)  {\n","\t\tif (tid < stride)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","\n","/*\n"," * MAIN: test on parallel reduction\n"," */\n","int main(void) {\n","\tint *a, *b, *d_a, *d_b;\n","\tint blockSize = 1024;            // block dim 1D\n","\tulong numBlock = 2*1024*1024;      // grid dim 1D\n","\tulong n = blockSize * numBlock;  // array dim\n","\tlong sum_CPU = 0, sum_GPU;\n","\tlong nByte = n*sizeof(int), mByte = numBlock * sizeof(int);\n","\tdouble start, stopGPU, stopCPU, speedup;\n","\n","\tprintf(\"\\n****  test on parallel reduction  ****\\n\");\n","\n","\t// init\n","\ta = (int *) malloc(nByte);\n","\tb = (int *) malloc(mByte);\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\n","\tCHECK(cudaMalloc((void **) &d_a, nByte));\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void **) &d_b, mByte));\n","\tCHECK(cudaMemset((void *) d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*                     CPU reduction                       */\n","\t/***********************************************************/\n","\tprintf(\"  Vector length: %.2f MB\\n\",n/(1024.0*1024.0));\n","\tprintf(\"\\n  CPU procedure...\\n\");\n","\tstart = seconds();\n","\tfor (ulong i = 0; i < n; i++) \n","    sum_CPU += a[i];\n","\tstopCPU = seconds() - start;\n","\tprintf(\"    Elapsed time: %f (sec) \\n\", stopCPU);\n","\tprintf(\"    sum: %lu\\n\",sum_CPU);\n","\n","\tprintf(\"\\n  GPU kernels (mem required %lu bytes)\\n\", nByte);\n","\n","\t/***********************************************************/\n","\t/*         KERNEL blockParReduce1 (divergent)              */\n","\t/***********************************************************/\n","\t// block by block parallel implementation with divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce1...\\n\");\n","\tstart = seconds();\n","\tblockParReduce1<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaGetLastError());\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\t\n","  // memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\t\n","  // check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++)\n","\t\tsum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\t// reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i]=1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t/***********************************************************/\n","\t/*        KERNEL blockParReduce2  (non divergent)          */\n","\t/***********************************************************/\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce2...\\n\");\n","\tstart = seconds();\n","\tblockParReduce2<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","\t\n","  // memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\t\n","  // check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) {\n","\t\tsum_GPU += b[i];\n","  //\t\tprintf(\"b[%d] = %d\\n\",i,b[i]);\n","\t}\n","\tassert(sum_GPU == n);\n","\t\n","  // reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++)\n","\t\tsum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\tcudaFree(d_a);\n","\n","\tCHECK(cudaDeviceReset());\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIOextPZMiav"},"source":["#Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 parReduce.cu -o parReduce\n","!parReduce"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IkYKd9J32ewH"},"source":["#Istogramma di un'immagine BMP"]},{"cell_type":"code","metadata":{"id":"Rbedjc-G23MM"},"source":["#@title working directory: **histogram**\n","%cd /home/grossi/CUDA/lab3/histogram/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G18uZY3t2kFp"},"source":["%%writefile /home/grossi/CUDA/lab3/histogram/hist.cu\n","/**\n"," * hist.cu\n"," */\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <time.h>\n","#include <limits.h>\n","\n","#include \"../utils/ImageStuff.h\"\n","#include \"../utils/common.h\"\n","\n","/*\n"," * Kernel 1D that computes histogram on GPU\n"," */\n","__global__ void histogramBMP(uint *bins, const pel *imgSrc, const uint W, const uint N, const uint M) {\n","\t// ** pixel granularity **\n","\tuint x = blockDim.x * blockIdx.x + threadIdx.x; // 1D pixel linear index over [0:W*H)\n","\tuint nrows = x / W;                             // num of rows to skip\n","\tuint off = x % W;                               // offset (= col) within current row\n","\n","\tif (x >= N)                        // pixel out of range\n","\t\treturn;\n","\n","\t//  ** byte granularity **\n","\tuint p = M * nrows + 3*off;        // src byte position of the pixel\n","\tpel R = imgSrc[p];\n","\tpel G = imgSrc[p+1];\n","\tpel B = imgSrc[p+2];\n","\tatomicAdd(&bins[R], 1);\n","\tatomicAdd(&bins[G+256], 1);\n","\tatomicAdd(&bins[B+512], 1);\n","}\n","\n","/*\n"," * Function that computes histogram on CPU\n"," */\n","void hist_CPU(uint *bins, const pel *imgSrc, const uint W, const uint H, const uint M) {\n","\tfor (int i = 0; i < W*H; i++) {\n","\t\tuint r = i / W;              // row of the source pixel\n","\t\tuint off = i - r * W;        // col of the source pixel\n","\n","\t\t//  ** byte granularity **\n","\t\tuint p = M * r + 3*off;      // src byte position of the pixel\n","\t\tpel R = imgSrc[p];\n","\t\tpel G = imgSrc[p+1];\n","\t\tpel B = imgSrc[p+2];\n","\t\tbins[R] += 1;\n","\t\tbins[G+256] += 1;\n","\t\tbins[B+512] += 1;\n","\t}\n","}\n","\n","int main(int argc, char **argv) {\n","\n","\tuint dimBlock = 1024;\n","\tpel *imgBMP_CPU;     // Where images are stored in CPU\n","\tpel *imgBMP_GPU;\t // Where images are stored in GPU\n","\n","\tuint *binsRGB_CPU, *binsRGB_GPU, *binsRGB_GPU2CPU;\n","\tuint N_bins = 3*256;\n","\tuint bin_size = N_bins*sizeof(uint);\n","\n","\tif (argc > 2)\n","\t\tdimBlock = atoi(argv[2]);\n","\telse if (argc < 2) {\n","\t\tprintf(\"\\n\\nUsage:  hist InputFilename dimBlock\\n\");\n","\t\texit(EXIT_FAILURE);\n","\t}\n","\n","\t// bins for CPU & GPU\n","\tbinsRGB_CPU = (uint*) calloc(N_bins, sizeof(uint));\n","\tbinsRGB_GPU2CPU = (uint*) malloc(bin_size);\n","\tCHECK(cudaMalloc((void**) &binsRGB_GPU, bin_size));\n","\n","\t// Create CPU memory to store the input image\n","\timgBMP_CPU = ReadBMPlin(argv[1]);\n","\tif (imgBMP_CPU == NULL) {\n","\t\tprintf(\"Cannot allocate memory for the input image...\\n\");\n","\t\texit(EXIT_FAILURE);\n","\t}\n","\n","\t// Allocate GPU buffer for image and bins\n","\tCHECK(cudaMalloc((void**) &imgBMP_GPU, IMAGESIZE));\n","\n","\t// Copy input vectors from host memory to GPU buffers.\n","\tCHECK(cudaMemcpy(imgBMP_GPU, imgBMP_CPU, IMAGESIZE, cudaMemcpyHostToDevice));\n","\n","\t// CPU histogram\n","\tdouble start = seconds();   // start time\n","\thist_CPU(binsRGB_CPU, imgBMP_CPU, WIDTH, HEIGHT, WIDTHB);\n","\tdouble stop = seconds();   // elapsed time\n","\tprintf(\"\\nCPU elapsed time %f sec \\n\\n\", stop - start);\n","\n","\t// invoke kernels (define grid and block sizes)\n","\tuint nPixels = WIDTH*HEIGHT;\n","\tint dimGrid = (nPixels + dimBlock - 1) / dimBlock;\n","\tprintf(\"\\ndimGrid = %d   dimBlock = %d\\n\",dimGrid,dimBlock);\n","\n","\tstart = seconds();   // start time\n","\thistogramBMP<<<dimGrid, dimBlock>>>(binsRGB_GPU, imgBMP_GPU, WIDTH, nPixels, WIDTHB);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstop = seconds();   // elapsed time\n","\tprintf(\"\\nGPU elapsed time %f sec \\n\\n\", stop - start);\n","\n","\t// Copy output (results) from GPU buffer to host (CPU) memory.\n","\tCHECK(cudaMemcpy(binsRGB_GPU2CPU, binsRGB_GPU, bin_size, cudaMemcpyDeviceToHost));\n","\n","\tfor (int i = 0; i < N_bins/3; i++)\n","\t\tprintf(\"bin_GPU[%d] = \\t%d\\t%d\\t%d\\t -- bin_CPU[%d] = \\t%d\\t%d\\t%d\\n\", i,\n","\t\t\t\tbinsRGB_GPU2CPU[i],binsRGB_GPU2CPU[i+256],binsRGB_GPU2CPU[i+512],\n","\t\t\t\ti,binsRGB_CPU[i],binsRGB_CPU[i+256],binsRGB_CPU[i+512]);\n","\n","\t// Deallocate GPU memory\n","\tcudaFree(imgBMP_GPU);\n","\tcudaFree(binsRGB_GPU);\n","\n","\t// tracing tools spel as Parallel Nsight and Visual Profiler to show complete traces.\n","\tCHECK(cudaDeviceReset());\n","\n","\treturn (EXIT_SUCCESS);\n","}\n","\n","/*\n"," *  Read a 24-bit/pixel BMP file into a 1D linear array.\n"," *  Allocate memory to store the 1D image and return its pointer\n"," */\n","pel *ReadBMPlin(char* fn) {\n","\tstatic pel *Img;\n","\tFILE* f = fopen(fn, \"rb\");\n","\tif (f == NULL) {\n","\t\tprintf(\"\\n\\n%s NOT FOUND\\n\\n\", fn);\n","\t\texit(EXIT_FAILURE);\n","\t}\n","\n","\tpel HeaderInfo[54];\n","\tsize_t nByte = fread(HeaderInfo, sizeof(pel), 54, f); // read the 54-byte header\n","\t// extract image height and width from header\n","\tint width = *(int*) &HeaderInfo[18];\n","\timg.width = width;\n","\tint height = *(int*) &HeaderInfo[22];\n","\timg.height = height;\n","\tint RowBytes = (width * 3 + 3) & (~3);  // row is multiple of 4 pixel\n","\timg.rowByte = RowBytes;\n","\t//save header for re-use\n","\tmemcpy(img.headInfo, HeaderInfo, 54);\n","\tprintf(\"\\n Input File name: %5s  (%d x %d)   File Size=%lu\", fn, img.width, img.height, IMAGESIZE);\n","\n","\t// allocate memory to store the main image (1 Dimensional array)\n","\tImg = (pel *) malloc(IMAGESIZE);\n","\tif (Img == NULL)\n","\t\treturn Img;      // Cannot allocate memory\n","\t// read the image from disk\n","\tsize_t out = fread(Img, sizeof(pel), IMAGESIZE, f);\n","\tfclose(f);\n","\treturn Img;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FvvbqpV-3gLH"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 hist.cu ../utils/ImageStuff.c -o hist\n","!hist"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["#Prodotto MQDB CUDA\n","MQDB base (su CPU) introdotto in lab1"]},{"cell_type":"code","metadata":{"id":"-_tGfHL2aRiB"},"source":["#@title working directory: **MQDB-CUDA**\n","%cd /home/grossi/CUDA/lab3/MQDB-CUDA\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVQVpcvKjkIk"},"source":["%%writefile /home/grossi/CUDA/lab3/MQDB-CUDA/mqdb_prod.cu\n","\n","#include \"../../utils/MQDB/mqdb.h\"\n","#include \"../../utils/common.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","\n","struct tms {\n","\tdouble CPUtms;\n","\tdouble GPUtmsNaive;\n","\tdouble GPUtmsMQDB;\n","\tfloat density;\n","};\n","\n","/*\n"," * Kernel for standard (naive) matrix product\n"," */\n","__global__ void matProd(mqdb A, mqdb B, mqdb C, int n) {\n","\t// row & col indexes\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < n) && (col < n)) {\n","\t\tfloat val = 0;\n","\t\tfor (int k = 0; k < n; k++)\n","\t\t\tval += A.elem[row * n + k] * B.elem[k * n + col];\n","\t\tC.elem[row * n + col] = val;\n","\t}\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb\n"," */\n","__global__ void mqdbBlockProd(mqdb A, mqdb B, mqdb C, int sdim, int d, int n) {\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// jump to the right block sub-matrix\n","\tint  offset = (n+1)*sdim;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < d) && (col < d)) {\n","\t\tfloat val = 0;\n","\n","\t\tfor (int k = 0; k < d; k++)\n","\t\t\tval += A.elem[row * n + k + offset] * B.elem[k * n + col + offset];\n","\t\tC.elem[row * n + col + offset] = val;\n","\t}\n","}\n","\n","/*\n"," * Test on MQDB kernels\n"," */\n","void testKernelsMQDB(uint n, uint k, struct tms* times) {\n","\n","\t// mqdb host matrices\n","\tmqdb A, B, C, C1;\n","\n","\t// mqdb device matrices\n","\tmqdb d_A, d_B, d_C;\n","\n","\t// fill in\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\tC1 = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\t// malloc and copy on device memory\n","\td_A.nBlocks = A.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_A.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_A.blkSize, A.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_A.elem, nBytes));\n","\tCHECK(cudaMemcpy(d_A.elem, A.elem, nBytes, cudaMemcpyHostToDevice));\n","\td_B.nBlocks = B.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_B.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_B.blkSize, B.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_B.elem, nBytes));\n","\tCHECK(cudaMemcpy(d_B.elem, B.elem, nBytes, cudaMemcpyHostToDevice));\n","\td_C.nBlocks = C.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_C.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_C.blkSize, C.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_C.elem, nBytes));\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*                    CPU MQDB product                     */\n","\t/***********************************************************/\n","\tprintf(\"CPU MQDB product...\\n\");\n","\tdouble start = seconds();\n","\tmqdbProd(A,B,C);\n","\tdouble CPUTime = seconds() - start;\n","\tprintf(\"   CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","\t/***********************************************************/\n","\t/*                     GPU mat product                     */\n","\t/***********************************************************/\n","\tprintf(\"Kernel (naive) mat product...\\n\");\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((n + block.x - 1) / block.x, (n + block.y - 1) / block.y);\n","\tstart = seconds();\n","\tmatProd<<<grid, block>>>(d_A, d_B, d_C, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble GPUtime1 = seconds() - start;\n","\tprintf(\"   elapsed time:                %.2f (sec)\\n\", GPUtime1);\n","\tprintf(\"   speedup vs CPU MQDB product: %.2f\\n\", CPUTime/GPUtime1);\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\tcheckResult(C,C1);\n","\t//\tmqdbDisplay(C1);\n","\n","\t/***********************************************************/\n","\t/*                     GPU MQDB product                    */\n","\t/***********************************************************/\n","\tprintf(\"Kernel MQDB product...\\n\");\n","\tuint sdim = 0;\n","\tstart = seconds();\n","\tfor (uint i = 0; i < k; i++ ) {\n","\t\tuint d = A.blkSize[i];\n","\t\tmqdbBlockProd<<<grid, block>>>(d_A, d_B, d_C, sdim, d, n);\n","\t\tsdim += d;\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble GPUtime2 = seconds() - start;\n","\tprintf(\"   elapsed time:                    %.2f (sec)\\n\", GPUtime2);\n","\tprintf(\"   speedup vs CPU MQDB product:     %.2f\\n\", CPUTime/GPUtime2);\n","\tprintf(\"   speedup vs GPU std mat product:  %.2f\\n\", GPUtime1/GPUtime2);\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\tcheckResult(C,C1);\n","\n","\tCHECK(cudaFree(d_A.elem));\n","\tCHECK(cudaFree(d_B.elem));\n","\tCHECK(cudaFree(d_C.elem));\n","\n","\t// collect times\n","\ttimes->CPUtms = CPUTime;\n","\ttimes->GPUtmsNaive = GPUtime1;\n","\ttimes->GPUtmsMQDB = GPUtime2;\n","\t\n","\tfloat den = 0;\n","\tfor (uint j = 0; j < k; j++)\n","\t\tden += A.blkSize[j]*A.blkSize[j];\n","\ttimes->density = den/(n*n);\n","}\n","\n","/*\n"," * main function\n"," */\n","int main(int argc, char *argv[]) {\n","\tuint n = 16*1024;      // matrix size\n","\tuint min_k = 30;       // max num of blocks\n","\tuint max_k = 30;       // max num of blocks\n","\n","\tstruct tms times[max_k-min_k+1];\n","\n","\t// multiple tests on kernels\n","\tfor (uint k = min_k; k <= max_k; k++) {\n","\t\tprintf(\"\\n*****   k = %d --- (avg block size = %f)\\n\",k,(float)n/k);\n","\t\ttestKernelsMQDB(n, k, &times[k-min_k]);\n","\t}\n","\n","\tFILE *fd;\n","\tfd = fopen(\"res.csv\", \"w\");\n","\tif (fd == NULL) {\n","\t\tperror(\"file error!\\n\");\n","\t\texit(1);\n","\t}\n","\n","\t// write results on file\n","\tfprintf(fd,\"num blocks,\");\n","\t\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\t\tfprintf(fd,\"%d,\",j+min_k);\n","\n","\tfprintf(fd,\"\\nCPU MQDB product,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].CPUtms);\n","\n","\tfprintf(fd,\"\\nKernel mat product naive,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsNaive);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDB);\n","\n","\tfprintf(fd,\"\\ndensity,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].density);\n","\n","\tfclose(fd);\n","\n","\treturn 0;\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 mqdb_prod.cu ../../utils/MQDB/mqdb.cpp  -o mqdb_prod\n","!mqdb_prod"],"execution_count":null,"outputs":[]}]}