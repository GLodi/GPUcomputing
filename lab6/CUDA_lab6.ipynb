{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab6.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["F9PmBZql0ow4","7yZYCuVxpngN","iUYP4kCJhEIx","vXUIQkZLCTcG","SOFMQZAkjlLW","SbQlRthtJTQE"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyMJ0x+F6txEKSmq3CB5Cm5N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g4gyOZKkHDVU"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo#scrollTo=g4gyOZKkHDVU)"]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# ✔ CUDA setup"]},{"cell_type":"code","metadata":{"id":"p9RIwaPbVQHV"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5YlC1IOTlNb"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV0CidyVeqU"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv2zAXZOu02V"},"source":["%cd /home/grossi/CUDA\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yZYCuVxpngN"},"source":["# ✔ VS code on Colab"]},{"cell_type":"code","metadata":{"id":"DKHvaMw3puK7"},"source":["# 1. Install the colab-code package...\n","!pip install colabcode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIGztaKepvqO"},"source":["# 2. Import and launch...\n","from colabcode import ColabCode\n","ColabCode()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ✔ DeviceQuery"]},{"cell_type":"code","metadata":{"id":"kW9b_Yuxi7id"},"source":["# DeviceQuery dell'attuale device\n","!nvcc /home/grossi/CUDA/lab4/deviceQuery/deviceQuery.cu -o deviceQuery\n","!deviceQuery"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0p_ObzYc1WNz"},"source":["%%writefile /home/grossi/CUDA/lab6/unified_mem/zero_copy.cu\n","\n","#include <stdio.h>\n","#include \"../../utils/common.h\"\n","\n","/*\n"," * This example demonstrates the use of zero-copy memory to remove the need to\n"," * explicitly issue a memcpy operation between the host and device. By mapping\n"," * host, page-locked memory into the device's address space, the address can\n"," * directly reference a host array and transfer its contents over the PCIe bus.\n"," *\n"," * This example compares performing a vector addition with and without zero-copy\n"," * memory.\n"," */\n","\n","void checkResult(float *hostRef, float *gpuRef, const int N) {\n","\tdouble epsilon = 1.0E-8;\n","\n","\tfor (int i = 0; i < N; i++) {\n","\t\tif (abs(hostRef[i] - gpuRef[i]) > epsilon) {\n","\t\t\tprintf(\"Arrays do not match!\\n\");\n","\t\t\tprintf(\"host %5.2f gpu %5.2f at current %d\\n\", hostRef[i], gpuRef[i], i);\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","\treturn;\n","}\n","\n","void initialData(float *ip, int size) {\n","\tint i;\n","\n","\tfor (i = 0; i < size; i++) {\n","\t\tip[i] = (float) (rand() & 0xFF) / 10.0f;\n","\t}\n","\n","\treturn;\n","}\n","\n","void sumArraysOnHost(float *A, float *B, float *C, const int N) {\n","\tfor (int idx = 0; idx < N; idx++) {\n","\t\tC[idx] = A[idx] + B[idx];\n","\t}\n","}\n","\n","__global__ void sumArrays(float *A, float *B, float *C, const int N) {\n","\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\tif (i < N)\n","\t\tC[i] = A[i] + B[i];\n","}\n","\n","__global__ void sumArraysZeroCopy(float *A, float *B, float *C, const int N) {\n","\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\tif (i < N)\n","\t\tC[i] = A[i] + B[i];\n","}\n","\n","int main(int argc, char **argv) {\n","\t// set up device\n","\tint dev = 0;\n","\tCHECK(cudaSetDevice(dev));\n","\n","\t// get device properties\n","\tcudaDeviceProp deviceProp;\n","\tCHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","\n","\t// check if support mapped memory\n","\tif (!deviceProp.canMapHostMemory) {\n","\t\tprintf(\"Device %d does not support mapping CPU host memory!\\n\", dev);\n","\t\tCHECK(cudaDeviceReset());\n","\t\texit (EXIT_SUCCESS);\n","\t}\n","\n","\tprintf(\"Using Device %d: %s \", dev, deviceProp.name);\n","\n","\t// set up data size of vectors\n","\tint ipower = 22;\n","\n","\tint nElem = (1 << ipower);\n","\tsize_t nBytes = nElem * sizeof(float);\n","\n","\tif (ipower < 18) {\n","\t\tprintf(\"Vector size %d power %d  nbytes  %3.0f KB\\n\", nElem, ipower,\n","\t\t\t\t(float) nBytes / (1024.0f));\n","\t} else {\n","\t\tprintf(\"Vector size %d power %d  nbytes  %3.0f MB\\n\", nElem, ipower,\n","\t\t\t\t(float) nBytes / (1024.0f * 1024.0f));\n","\t}\n","\n","\t// part 1: using device memory\n","\t// malloc host memory\n","\tfloat *h_A, *h_B, *hostRef, *gpuRef;\n","\th_A = (float *) malloc(nBytes);\n","\th_B = (float *) malloc(nBytes);\n","\thostRef = (float *) malloc(nBytes);\n","\tgpuRef = (float *) malloc(nBytes);\n","\n","\t// initialize data at host side\n","\tinitialData(h_A, nElem);\n","\tinitialData(h_B, nElem);\n","\tmemset(hostRef, 0, nBytes);\n","\tmemset(gpuRef, 0, nBytes);\n","\n","\t// add vector at host side for result checks\n","\tsumArraysOnHost(h_A, h_B, hostRef, nElem);\n","\n","\t// malloc device global memory\n","\tfloat *d_A, *d_B, *d_C;\n","\tCHECK(cudaMalloc((float**) &d_A, nBytes));\n","\tCHECK(cudaMalloc((float**) &d_B, nBytes));\n","\tCHECK(cudaMalloc((float**) &d_C, nBytes));\n","\n","\t// transfer data from host to device\n","\tCHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));\n","\n","\t// set up execution configuration\n","\tint iLen = 512;\n","\tdim3 block(iLen);\n","\tdim3 grid((nElem + block.x - 1) / block.x);\n","\n","\tsumArrays<<<grid, block>>>(d_A, d_B, d_C, nElem);\n","\n","\t// free device global memory\n","\tCHECK(cudaFree(d_A));\n","\tCHECK(cudaFree(d_B));\n","\n","\t// free host memory\n","\tfree(h_A);\n","\tfree(h_B);\n","\n","\t// part 2: using zerocopy memory for array A and B\n","\t// allocate zerocpy memory\n","\tCHECK(cudaHostAlloc((void **) &h_A, nBytes, cudaHostAllocMapped));\n","\tCHECK(cudaHostAlloc((void **) &h_B, nBytes, cudaHostAllocMapped));\n","\n","\t// initialize data at host side\n","\tinitialData(h_A, nElem);\n","\tinitialData(h_B, nElem);\n","\tmemset(hostRef, 0, nBytes);\n","\tmemset(gpuRef, 0, nBytes);\n","\n","\t// pass the pointer to device\n","\tCHECK(cudaHostGetDevicePointer((void **) &d_A, (void *) h_A, 0));\n","\tCHECK(cudaHostGetDevicePointer((void **) &d_B, (void *) h_B, 0));\n","\n","\t// add at host side for result checks\n","\tsumArraysOnHost(h_A, h_B, hostRef, nElem);\n","\n","\t// execute kernel with zero copy memory\n","\tsumArraysZeroCopy<<<grid, block>>>(d_A, d_B, d_C, nElem);\n","\n","\t// copy kernel result back to host side\n","\tCHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));\n","\n","\t// check device results\n","\tcheckResult(hostRef, gpuRef, nElem);\n","\n","\t// free  memory\n","\tCHECK(cudaFree(d_C));\n","\tCHECK(cudaFreeHost(h_A));\n","\tCHECK(cudaFreeHost(h_B));\n","\n","\tfree(hostRef);\n","\tfree(gpuRef);\n","\n","\t// reset device\n","\tCHECK(cudaDeviceReset());\n","\treturn EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaxOHvNp1885"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 zero_copy.cu  -o zero_copy\n","!zero_copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eoAbu3B2RvP"},"source":["!nvprof ./zero_copy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# Unified memory ★\n"]},{"cell_type":"code","metadata":{"id":"lMElD9hZCUcg"},"source":["#@title working directory: **unified_mem**\n","%cd /home/grossi/CUDA/lab6/unified_mem\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%writefile /home/grossi/CUDA/lab6/unified_mem/sumMatrixGPU.cu\n","\n","#include <stdio.h>\n","#include \"../../utils/common.h\"\n","\n","void initialData(float *ip, const int size) {\n","  int i;\n","\n","  for (i = 0; i < size; i++)\n","    ip[i] = (float)( rand() & 0xFF ) / 10.0f;\n","  return;\n","}\n","\n","void sumMatrixOnHost(float *A, float *B, float *C, const int nx, const int ny) {\n","  float *ia = A;\n","  float *ib = B;\n","  float *ic = C;\n","\n","  for (int iy = 0; iy < ny; iy++) {\n","    for (int ix = 0; ix < nx; ix++)\n","      ic[ix] = ia[ix] + ib[ix];\n","\n","    ia += nx;\n","    ib += nx;\n","    ic += nx;\n","  }\n","  return;\n","}\n","\n","void checkResult(float *hostRef, float *gpuRef, const int N) {\n","  double epsilon = 1.0E-8;\n","  bool match = 1;\n","\n","  for (int i = 0; i < N; i++) {\n","    if (abs(hostRef[i] - gpuRef[i]) > epsilon) {\n","      match = 0;\n","      printf(\"host %f gpu %f\\n\", hostRef[i], gpuRef[i]);\n","      break;\n","    }\n","  }\n","\n","  if (!match)\n","    printf(\"Arrays do not match.\\n\\n\");\n","}\n","\n","// grid 2D block 2D\n","__global__ void sumMatrixGPU(float *MatA, float *MatB, float *MatC, int nx, int ny) {\n","  unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n","  unsigned int iy = threadIdx.y + blockIdx.y * blockDim.y;\n","  unsigned int idx = iy * nx + ix;\n","\n","  if (ix < nx && iy < ny)\n","    MatC[idx] = MatA[idx] + MatB[idx];\n","}\n","\n","int main(int argc, char **argv) {\n","  printf(\"%s Starting \", argv[0]);\n","\n","  // set up device\n","  int dev = 0;\n","  cudaDeviceProp deviceProp;\n","  CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","  printf(\"using Device %d: %s\\n\", dev, deviceProp.name);\n","  CHECK(cudaSetDevice(dev));\n","\n","  // set up data size of matrix\n","  int nx, ny;\n","  int ishift = 14;\n","\n","  if  (argc > 1) ishift = atoi(argv[1]);\n","\n","  nx = ny = 1 << ishift;\n","\n","  int nxy = nx * ny;\n","  int nBytes = nxy * sizeof(float);\n","  printf(\"Matrix size: nx %d ny %d\\n\", nx, ny);\n","\n","  // malloc host memory\n","  float *A, *B, *hostRef, *gpuRef;\n","  CHECK(cudaMallocManaged((void **)&A, nBytes));\n","  CHECK(cudaMallocManaged((void **)&B, nBytes));\n","  CHECK(cudaMallocManaged((void **)&gpuRef,  nBytes);  );\n","  CHECK(cudaMallocManaged((void **)&hostRef, nBytes););\n","\n","  // initialize data at host side\n","  double iStart = seconds();\n","  initialData(A, nxy);\n","  initialData(B, nxy);\n","  double iElaps = seconds() - iStart;\n","  printf(\"initialization: \\t %f sec\\n\", iElaps);\n","\n","  memset(hostRef, 0, nBytes);\n","  memset(gpuRef, 0, nBytes);\n","\n","  // add matrix at host side for result checks\n","  iStart = seconds();\n","  sumMatrixOnHost(A, B, hostRef, nx, ny);\n","  iElaps = seconds() - iStart;\n","  printf(\"sumMatrix on host:\\t %f sec\\n\", iElaps);\n","\n","  // invoke kernel at host side\n","  int dimx = 32;\n","  int dimy = 32;\n","  dim3 block(dimx, dimy);\n","  dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);\n","\n","  // warm-up kernel, with unified memory all pages will migrate from host to device\n","  sumMatrixGPU<<<grid, block>>>(A, B, gpuRef, 1, 1);\n","\n","  // after warm-up, time with unified memory\n","  iStart = seconds();\n","\n","  sumMatrixGPU<<<grid, block>>>(A, B, gpuRef, nx, ny);\n","\n","  CHECK(cudaDeviceSynchronize());\n","  iElaps = seconds() - iStart;\n","  printf(\"sumMatrix on gpu :\\t %f sec <<<(%d,%d), (%d,%d)>>> \\n\", iElaps,\n","          grid.x, grid.y, block.x, block.y);\n","\n","  // check kernel error\n","  CHECK(cudaGetLastError());\n","\n","  // check device results\n","  checkResult(hostRef, gpuRef, nxy);\n","\n","  // free device global memory\n","  CHECK(cudaFree(A));\n","  CHECK(cudaFree(B));\n","  CHECK(cudaFree(hostRef));\n","  CHECK(cudaFree(gpuRef));\n","\n","  // reset device\n","  CHECK(cudaDeviceReset());\n","\n","  return (0);\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 sumMatrixGPU.cu  -o sumMatrixGPU\n","!sumMatrixGPU 14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfR471rze2p-"},"source":["# profilazione (senza unified memory - dà errore)\n","\n","!nvprof --unified-memory-profiling off ./sumMatrixGPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mykWw4i6-PTq"},"source":["%%writefile /home/grossi/CUDA/lab6/unified_mem/sumMatrixGPUManual.cu\n","\n","#include <stdio.h>\n","#include \"../../utils/common.h\"\n","\n","void initialData(float *ip, const int size) {\n","  int i;\n","\n","  for (i = 0; i < size; i++)\n","    ip[i] = (float)( rand() & 0xFF ) / 10.0f;\n","  return;\n","}\n","\n","void sumMatrixOnHost(float *A, float *B, float *C, const int nx, const int ny) {\n","  float *ia = A;\n","  float *ib = B;\n","  float *ic = C;\n","\n","  for (int iy = 0; iy < ny; iy++) {\n","    for (int ix = 0; ix < nx; ix++)\n","      ic[ix] = ia[ix] + ib[ix];\n","\n","    ia += nx;\n","    ib += nx;\n","    ic += nx;\n","  }\n","  return;\n","}\n","\n","void checkResult(float *hostRef, float *gpuRef, const int N) {\n","  double epsilon = 1.0E-8;\n","  bool match = 1;\n","\n","  for (int i = 0; i < N; i++) {\n","    if (abs(hostRef[i] - gpuRef[i]) > epsilon) {\n","      match = 0;\n","      printf(\"host %f gpu %f\\n\", hostRef[i], gpuRef[i]);\n","      break;\n","    }\n","  }\n","\n","  if (!match)\n","    printf(\"Arrays do not match.\\n\\n\");\n","}\n","\n","// grid 2D block 2D\n","__global__ void sumMatrixGPU(float *MatA, float *MatB, float *MatC, int nx, int ny) {\n","  unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n","  unsigned int iy = threadIdx.y + blockIdx.y * blockDim.y;\n","  unsigned int idx = iy * nx + ix;\n","\n","  if (ix < nx && iy < ny)\n","    MatC[idx] = MatA[idx] + MatB[idx];\n","}\n","\n","int main(int argc, char **argv) {\n","    printf(\"%s Starting \", argv[0]);\n","\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"using Device %d: %s\\n\", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","\n","    // set up data size of matrix\n","    int nx, ny;\n","    int ishift = 12;\n","\n","    if  (argc > 1) ishift = atoi(argv[1]);\n","\n","    nx = ny = 1 << ishift;\n","\n","    int nxy = nx * ny;\n","    int nBytes = nxy * sizeof(float);\n","    printf(\"Matrix size: nx %d ny %d\\n\", nx, ny);\n","\n","    // malloc host memory\n","    float *h_A, *h_B, *hostRef, *gpuRef;\n","    h_A = (float *)malloc(nBytes);\n","    h_B = (float *)malloc(nBytes);\n","    hostRef = (float *)malloc(nBytes);\n","    gpuRef = (float *)malloc(nBytes);\n","\n","    // initialize data at host side\n","    double iStart = seconds();\n","    initialData(h_A, nxy);\n","    initialData(h_B, nxy);\n","    double iElaps = seconds() - iStart;\n","\n","    printf(\"initialization: \\t %f sec\\n\", iElaps);\n","\n","    memset(hostRef, 0, nBytes);\n","    memset(gpuRef, 0, nBytes);\n","\n","    // add matrix at host side for result checks\n","    iStart = seconds();\n","    sumMatrixOnHost(h_A, h_B, hostRef, nx, ny);\n","    iElaps = seconds() - iStart;\n","    printf(\"sumMatrix on host:\\t %f sec\\n\", iElaps);\n","\n","    // malloc device global memory\n","    float *d_MatA, *d_MatB, *d_MatC;\n","    CHECK(cudaMalloc((void **)&d_MatA, nBytes));\n","    CHECK(cudaMalloc((void **)&d_MatB, nBytes));\n","    CHECK(cudaMalloc((void **)&d_MatC, nBytes));\n","\n","    // invoke kernel at host side\n","    int dimx = 32;\n","    int dimy = 32;\n","    dim3 block(dimx, dimy);\n","    dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);\n","\n","    // init device data to 0.0f, then warm-up kernel to obtain accurate timing\n","    // result\n","    CHECK(cudaMemset(d_MatA, 0.0f, nBytes));\n","    CHECK(cudaMemset(d_MatB, 0.0f, nBytes));\n","    sumMatrixGPU<<<grid, block>>>(d_MatA, d_MatB, d_MatC, 1, 1);\n","\n","\n","    // transfer data from host to device\n","    CHECK(cudaMemcpy(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice));\n","    CHECK(cudaMemcpy(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice));\n","\n","    iStart =  seconds();\n","    sumMatrixGPU<<<grid, block>>>(d_MatA, d_MatB, d_MatC, nx, ny);\n","\n","    CHECK(cudaDeviceSynchronize());\n","    iElaps = seconds() - iStart;\n","    printf(\"sumMatrix on gpu :\\t %f sec <<<(%d,%d), (%d,%d)>>> \\n\", iElaps,\n","            grid.x, grid.y, block.x, block.y);\n","\n","    CHECK(cudaMemcpy(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost));\n","\n","    // check kernel error\n","    CHECK(cudaGetLastError());\n","\n","    // check device results\n","    checkResult(hostRef, gpuRef, nxy);\n","\n","    // free device global memory\n","    CHECK(cudaFree(d_MatA));\n","    CHECK(cudaFree(d_MatB));\n","    CHECK(cudaFree(d_MatC));\n","\n","    // free host memory\n","    free(h_A);\n","    free(h_B);\n","    free(hostRef);\n","    free(gpuRef);\n","\n","    // reset device\n","    CHECK(cudaDeviceReset());\n","\n","    return (0);\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJcJtD6f_IXK"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 sumMatrixGPUManual.cu  -o sumMatrixGPUManual\n","!sumMatrixGPUManual 14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5JMDp3t_kEI"},"source":["# profilazione (senza unified memory - dà errore)\n","\n","!nvprof --unified-memory-profiling off ./sumMatrixGPUManual"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# SoA vs AoS structs ★"]},{"cell_type":"code","metadata":{"id":"-_tGfHL2aRiB"},"source":["#@title working directory: **struct**\n","%cd /home/grossi/CUDA/lab6/struct/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%writefile /home/grossi/CUDA/lab6/struct/SoA.cu\n","\n","\n","#include <stdio.h>\n","#include <stdint.h>\n","#include \"../../utils/common.h\"\n","\n","#define N 1<<24\n","#define blocksize 1<<7\n","\n","struct SoA {\n","\tuint8_t r[N];\n","\tuint8_t g[N];\n","\tuint8_t b[N];\n","};\n","\n","\n","void initialize(SoA*, int);\n","void checkResult(SoA*, SoA*, int);\n","\n","/*\n"," * Riscala l'immagine al valore massimo [max] fissato\n"," */\n","__global__ void rescaleImg(SoA *img, const int max, const int n) {\n","\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (i < n) {\n","\t\tfloat r,g,b;\n","\t\tSoA *tmp = img;\n","\t\tr = max * (float)tmp->r[i]/255.0f;\n","\t\timg->r[i] = (uint8_t)r;\n","\t\tg = max * (float)tmp->g[i]/255.0f;\n","\t\timg->g[i] = (uint8_t)g;\n","\t\tb = max * (float)tmp->b[i]/255.0f;\n","\t\timg->b[i] = (uint8_t)b;\n","\t}\n","}\n","\n","/*\n"," * cancella un piano dell'immagine [plane = 'r' o 'g' o 'b'] fissato\n"," */\n","__global__ void deletePlane(SoA *img, const char plane, const int n) {\n","\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (i < n) {\n","\t\tswitch (plane) {\n","\t\tcase 'r':\n","\t\t\timg->r[i] = 0;\n","\t\t\tbreak;\n","\t\tcase 'g':\n","\t\t\timg->g[i] = 0;\n","\t\t\tbreak;\n","\t\tcase 'b':\n","\t\t\timg->b[i] = 0;\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","}\n","\n","/*\n"," * setup device\n"," */\n","__global__ void warmup(SoA *img, const int max, const int n) {\n","\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (i < n) {\n","\t\tfloat r,g,b;\n","\t\tSoA *tmp = img;\n","\t\tr = max * (float)tmp->r[i]/255.0f;\n","\t\timg->r[i] = (uint8_t)r;\n","\t\tg = max * (float)tmp->g[i]/255.0f;\n","\t\timg->g[i] = (uint8_t)g;\n","\t\tb = max * (float)tmp->b[i]/255.0f;\n","\t\timg->b[i] = (uint8_t)b;\n","\t}\n","}\n","\n","/*\n"," * Legge da stdin quale kernel eseguire: 0 per rescaleImg, 1 per deletePlane\n"," */\n","int main(int argc, char **argv) {\n","\t// set up device\n","\tint dev = 0;\n","\tcudaDeviceProp deviceProp;\n","\tCHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","\tprintf(\"%s test SoA at \", argv[0]);\n","\tprintf(\"device %d: %s \\n\", dev, deviceProp.name);\n","\tCHECK(cudaSetDevice(dev));\n","\n","\t// scelta del kernel da eseguire\n","\tint kernel = 0;\n","\tif (argc > 1) kernel = atoi(argv[1]);\n","\n","\t// allocate host memory\n","\tsize_t nBytes = sizeof(SoA);\n","\tSoA *img = (SoA *)malloc(nBytes);\n","\tSoA *new_img = (SoA *)malloc(nBytes);\n","\n","\t// initialize host array\n","\tinitialize(img, N);\n","\n","\t// allocate device memory\n","\tint n_elem = N;\n","\tSoA *d_img;\n","\tCHECK(cudaMalloc((void**)&d_img, nBytes));\n","\n","\t// copy data from host to device\n","\tCHECK(cudaMemcpy(d_img, img, nBytes, cudaMemcpyHostToDevice));\n","\n","\t// definizione max\n","\tint max = 128;\n","\tif (argc > 2) max = atoi(argv[2]);\n","\n","\t// configurazione per esecuzione\n","\tdim3 block (blocksize, 1);\n","\tdim3 grid  ((n_elem + block.x - 1) / block.x, 1);\n","\n","\t// kernel 1: warmup\n","\tdouble iStart = seconds();\n","\twarmup<<<1, 32>>>(d_img, max, 32);\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble iElaps = seconds() - iStart;\n","\tprintf(\"warmup<<< 1, 32 >>> elapsed %f sec\\n\",iElaps);\n","\tCHECK(cudaGetLastError());\n","\n","\t// kernel 2 rescaleImg o deletePlane\n","\tiStart = seconds();\n","\tif (kernel == 0)\n","\t\trescaleImg<<<grid, block>>>(d_img, max, n_elem);\n","\telse\n","\t\tdeletePlane<<<grid, block>>>(d_img, 'r', n_elem);\n","\tCHECK(cudaDeviceSynchronize());\n","\tiElaps = seconds() - iStart;\n","\tprintf(\"rescaleImg <<< %3d, %3d >>> elapsed %f sec\\n\", grid.x, block.x, iElaps);\n","\tCHECK(cudaMemcpy(new_img, d_img, nBytes, cudaMemcpyDeviceToHost));\n","\tCHECK(cudaGetLastError());\n","\n","\t//checkResult(img, new_img, n_elem);\n","\n","\t// free memories both host and device\n","\tCHECK(cudaFree(d_img));\n","\tfree(img);\n","\tfree(new_img);\n","\n","\t// reset device\n","\tCHECK(cudaDeviceReset());\n","\treturn EXIT_SUCCESS;\n","}\n","\n","void initialize(SoA *img,  int size) {\n","\tfor (int i = 0; i < size; i++) {\n","\t\timg->r[i] = rand() % 256;\n","\t\timg->g[i] = rand() % 256;\n","\t\timg->b[i] = rand() % 256;\n","\t}\n","\treturn;\n","}\n","\n","void checkResult(SoA *img, SoA *new_img, int n_elem) {\n","\tfor (int i = 0; i < n_elem; i+=1000)\n","\t\tprintf(\"img[%d] = (%d,%d,%d) -- new_img[%d] = (%d,%d,%d)\\n\",\n","\t\t\t\ti,img->r[i],img->g[i],img->b[i],i,new_img->r[i],new_img->g[i],new_img->b[i]);\n","\treturn;\n","}\n","\n","\n","void transposeHost(float *out, float *in, const int nx, const int ny) {\n","\tfor (int iy = 0; iy < ny; ++iy) {\n","\t\tfor (int ix = 0; ix < nx; ++ix) {\n","\t\t\tout[ix * ny + iy] = in[iy * nx + ix];\n","\t\t}\n","\t}\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_60  SoA.cu -o SoA\n","!./SoA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bwcTDn6ehJr_"},"source":["%%writefile /home/grossi/CUDA/lab6/struct/AoS.cu\n","\n","\n","#include <stdio.h>\n","#include <stdint.h>\n","#include \"../../utils/common.h\"\n","\n","#define N 1<<24\n","#define blocksize 128\n","\n","struct AoS {\n","\tuint8_t r;\n","\tuint8_t g;\n","\tuint8_t b;\n","};\n","\n","void initialize(AoS *, int);\n","void checkResult(AoS *, AoS *, int);\n","\n","/*\n"," * Riscala l'immagine al valore massimo [max] fissato\n"," */\n","__global__ void rescaleImg(AoS *img, const int max, const int n) {\n","\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (i < n) {\n","\t\tfloat r,g,b;\n","\t\tAoS tmp = img[i];\n","\t\tr = max * (float)tmp.r/255.0f;\n","\t\ttmp.r = (uint8_t)r;\n","\t\tg = max * (float)tmp.g/255.0f;\n","\t\ttmp.g = (uint8_t)g;\n","\t\tb = max * (float)tmp.b/255.0f;\n","\t\ttmp.b = (uint8_t)b;\n","\t\timg[i] = tmp;\n","\t}\n","}\n","\n","/*\n"," * cancella un piano dell'immagine [plane = 'r' o 'g' o 'b'] fissato\n"," */\n","__global__ void deletePlane(AoS *img, const char plane, const int n) {\n","\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (i < n) {\n","\t\tswitch (plane) {\n","\t\tcase 'r':\n","\t\t\timg[i].r = 0;\n","\t\t\tbreak;\n","\t\tcase 'g':\n","\t\t\timg[i].g = 0;\n","\t\t\tbreak;\n","\t\tcase 'b':\n","\t\t\timg[i].b = 0;\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","}\n","\n","/*\n"," * setup device\n"," */\n","__global__ void warmup(AoS *img, const int max, const int n) {\n","\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (i < n) {\n","\t\tfloat r,g,b;\n","\t\tAoS tmp = img[i];\n","\t\tr = max * (float)tmp.r/255.0f;\n","\t\ttmp.r = (uint8_t)r;\n","\t\tg = max * (float)tmp.g/255.0f;\n","\t\ttmp.g = (uint8_t)g;\n","\t\tb = max * (float)tmp.b/255.0f;\n","\t\ttmp.b = (uint8_t)b;\n","\t\timg[i] = tmp;\n","\t}\n","}\n","\n","/*\n"," * Legge da stdin quale kernel eseguire: 0 per rescaleImg, 1 per deletePlane\n"," */\n","int main(int argc, char **argv) {\n","\t// set up device\n","\tint dev = 0;\n","\tcudaDeviceProp deviceProp;\n","\tCHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","\tprintf(\"%s test AoS at \", argv[0]);\n","\tprintf(\"device %d: %s \\n\", dev, deviceProp.name);\n","\tCHECK(cudaSetDevice(dev));\n","\n","\t// scelta del kernel da eseguire\n","\tint kernel = 0;\n","\tif (argc > 1) kernel = atoi(argv[1]);\n","\n","\t// allocate host memory\n","\tint n_elem = N;\n","\tsize_t nBytes = n_elem * sizeof(AoS);\n","\tAoS *img = (AoS *)malloc(nBytes);\n","\tAoS *new_img = (AoS *)malloc(nBytes);\n","\n","\t// initialize host array\n","\tinitialize(img, N);\n","\n","\t// allocate device memory\n","\tAoS *d_img;\n","\tCHECK(cudaMalloc((void**)&d_img, nBytes));\n","\n","\t// copy data from host to device\n","\tCHECK(cudaMemcpy(d_img, img, nBytes, cudaMemcpyHostToDevice));\n","\n","\t// definizione max\n","\tint max = 128;\n","\tif (argc > 2) max = atoi(argv[2]);\n","\n","\t// configurazione per esecuzione\n","\tdim3 block (blocksize, 1);\n","\tdim3 grid  ((n_elem + block.x - 1) / block.x, 1);\n","\n","\t// kernel 1: warmup\n","\tdouble iStart = seconds();\n","\twarmup<<<1, 32>>>(d_img, max, 32);\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble iElaps = seconds() - iStart;\n","\tprintf(\"warmup<<< 1, 32 >>> elapsed %f sec\\n\",iElaps);\n","\tCHECK(cudaGetLastError());\n","\n","\t// kernel 2 rescaleImg o deletePlane\n","\tiStart = seconds();\n","\tif (kernel == 0) {\n","\t\trescaleImg<<<grid, block>>>(d_img, max, n_elem);\n","\t\tprintf(\"rescaleImg <<< %3d, %3d >>> elapsed %f sec\\n\", grid.x, block.x, iElaps);\n","\t}\n","\telse {\n","\t\tdeletePlane<<<grid, block>>>(d_img, 'r', n_elem);\n","\t\tprintf(\"deletePlane <<< %3d, %3d >>> elapsed %f sec\\n\", grid.x, block.x, iElaps);\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tiElaps = seconds() - iStart;\n","\tCHECK(cudaMemcpy(new_img, d_img, nBytes, cudaMemcpyDeviceToHost));\n","\tCHECK(cudaGetLastError());\n","\n","\t//checkResult(img, new_img, n_elem);\n","\n","\t// free memories both host and device\n","\tCHECK(cudaFree(d_img));\n","\tfree(img);\n","\tfree(new_img);\n","\n","\t// reset device\n","\tCHECK(cudaDeviceReset());\n","\treturn EXIT_SUCCESS;\n","}\n","\n","void initialize(AoS *img,  int size) {\n","\tfor (int i = 0; i < size; i++) {\n","\t\timg[i].r = rand() % 256;\n","\t\timg[i].g = rand() % 256;\n","\t\timg[i].b = rand() % 256;\n","\t}\n","\treturn;\n","}\n","\n","void checkResult(AoS *img, AoS *new_img, int n_elem) {\n","\tfor (int i = 0; i < n_elem; i+=1000)\n","\t\tprintf(\"img[%d] = (%d,%d,%d) -- new_img[%d] = (%d,%d,%d)\\n\",\n","\t\t\t\ti,img[i].r,img[i].g,img[i].b,i,new_img[i].r,new_img[i].g,new_img[i].b);\n","\treturn;\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiun00TE2wcE"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_60  AoS.cu -o AoS\n","!./AoS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SbQlRthtJTQE"},"source":["# Transpose ★"]},{"cell_type":"code","metadata":{"id":"GxOUZhIUKAM1"},"source":["#@title working directory: **transpose**\n","%cd /home/grossi/CUDA/lab6/transpose/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmsEg15mJRLU"},"source":["%%writefile /home/grossi/CUDA/lab6/transpose/transpose.cu\n","\n","#include <stdio.h>\n","#include \"../../utils/common.h\"\n","\n","/*\n"," * Various memory access pattern optimizations applied to a matrix transpose\n"," * kernel.\n"," */\n","\n","#define BDIMX 16\n","#define BDIMY 16\n","\n","void initialData(float *in,  const int size)\n","{\n","    for (int i = 0; i < size; i++)\n","    {\n","        in[i] = (float)( rand() & 0xFF ) / 10.0f; //100.0f;\n","    }\n","\n","    return;\n","}\n","\n","void printData(float *in,  const int size)\n","{\n","    for (int i = 0; i < size; i++)\n","    {\n","        printf(\"%dth element: %f\\n\", i, in[i]);\n","    }\n","\n","    return;\n","}\n","\n","void checkResult(float *hostRef, float *gpuRef, const int size, int showme)\n","{\n","    double epsilon = 1.0E-8;\n","    bool match = 1;\n","\n","    for (int i = 0; i < size; i++)\n","    {\n","        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n","        {\n","            match = 0;\n","            printf(\"different on %dth element: host %f gpu %f\\n\", i, hostRef[i],\n","                    gpuRef[i]);\n","            break;\n","        }\n","\n","        if (showme && i > size / 2 && i < size / 2 + 5)\n","        {\n","            // printf(\"%dth element: host %f gpu %f\\n\",i,hostRef[i],gpuRef[i]);\n","        }\n","    }\n","\n","    if (!match)  printf(\"Arrays do not match.\\n\\n\");\n","}\n","\n","void transposeHost(float *out, float *in, const int nx, const int ny)\n","{\n","    for( int iy = 0; iy < ny; ++iy)\n","    {\n","        for( int ix = 0; ix < nx; ++ix)\n","        {\n","            out[ix * ny + iy] = in[iy * nx + ix];\n","        }\n","    }\n","}\n","\n","__global__ void warmup(float *out, float *in, const int nx, const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[iy * nx + ix] = in[iy * nx + ix];\n","    }\n","}\n","\n","// case 0 copy kernel: access data in rows\n","__global__ void copyRow(float *out, float *in, const int nx, const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[iy * nx + ix] = in[iy * nx + ix];\n","    }\n","}\n","\n","// case 1 copy kernel: access data in columns\n","__global__ void copyCol(float *out, float *in, const int nx, const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[ix * ny + iy] = in[ix * ny + iy];\n","    }\n","}\n","\n","// case 2 transpose kernel: read in rows and write in columns\n","__global__ void transposeNaiveRow(float *out, float *in, const int nx,\n","                                  const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[ix * ny + iy] = in[iy * nx + ix];\n","    }\n","}\n","\n","// case 3 transpose kernel: read in columns and write in rows\n","__global__ void transposeNaiveCol(float *out, float *in, const int nx,\n","                                  const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[iy * nx + ix] = in[ix * ny + iy];\n","    }\n","}\n","\n","// case 4 transpose kernel: read in rows and write in columns + unroll 4 blocks\n","__global__ void transposeUnroll4Row(float *out, float *in, const int nx,\n","                                    const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x * 4 + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    unsigned int ti = iy * nx + ix; // access in rows\n","    unsigned int to = ix * ny + iy; // access in columns\n","\n","    if (ix + 3 * blockDim.x < nx && iy < ny)\n","    {\n","        out[to]                   = in[ti];\n","        out[to + ny * blockDim.x]   = in[ti + blockDim.x];\n","        out[to + ny * 2 * blockDim.x] = in[ti + 2 * blockDim.x];\n","        out[to + ny * 3 * blockDim.x] = in[ti + 3 * blockDim.x];\n","    }\n","}\n","\n","// case 5 transpose kernel: read in columns and write in rows + unroll 4 blocks\n","__global__ void transposeUnroll4Col(float *out, float *in, const int nx,\n","                                    const int ny)\n","{\n","    unsigned int ix = blockDim.x * blockIdx.x * 4 + threadIdx.x;\n","    unsigned int iy = blockDim.y * blockIdx.y + threadIdx.y;\n","\n","    unsigned int ti = iy * nx + ix; // access in rows\n","    unsigned int to = ix * ny + iy; // access in columns\n","\n","    if (ix + 3 * blockDim.x < nx && iy < ny)\n","    {\n","        out[ti]                = in[to];\n","        out[ti +   blockDim.x] = in[to +   blockDim.x * ny];\n","        out[ti + 2 * blockDim.x] = in[to + 2 * blockDim.x * ny];\n","        out[ti + 3 * blockDim.x] = in[to + 3 * blockDim.x * ny];\n","    }\n","}\n","\n","/*\n"," * case 6 :  transpose kernel: read in rows and write in colunms + diagonal\n"," * coordinate transform\n"," */\n","__global__ void transposeDiagonalRow(float *out, float *in, const int nx,\n","                                     const int ny)\n","{\n","    unsigned int blk_y = blockIdx.x;\n","    unsigned int blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;\n","\n","    unsigned int ix = blockDim.x * blk_x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blk_y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[ix * ny + iy] = in[iy * nx + ix];\n","    }\n","}\n","\n","/*\n"," * case 7 :  transpose kernel: read in columns and write in row + diagonal\n"," * coordinate transform.\n"," */\n","__global__ void transposeDiagonalCol(float *out, float *in, const int nx,\n","                                     const int ny)\n","{\n","    unsigned int blk_y = blockIdx.x;\n","    unsigned int blk_x = (blockIdx.x + blockIdx.y) % gridDim.x;\n","\n","    unsigned int ix = blockDim.x * blk_x + threadIdx.x;\n","    unsigned int iy = blockDim.y * blk_y + threadIdx.y;\n","\n","    if (ix < nx && iy < ny)\n","    {\n","        out[iy * nx + ix] = in[ix * ny + iy];\n","    }\n","}\n","\n","// main functions\n","int main(int argc, char **argv)\n","{\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"%s starting transpose at \", argv[0]);\n","    printf(\"device %d: %s \", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","\n","    // set up array size 2048\n","    int nx = 1 << 12;\n","    int ny = 1 << 12;\n","\n","    // select a kernel and block size\n","    int iKernel = 0;\n","    int blockx = 16;\n","    int blocky = 16;\n","\n","    if (argc > 1) iKernel = atoi(argv[1]);\n","\n","    if (argc > 2) blockx  = atoi(argv[2]);\n","\n","    if (argc > 3) blocky  = atoi(argv[3]);\n","\n","    if (argc > 4) nx  = atoi(argv[4]);\n","\n","    if (argc > 5) ny  = atoi(argv[5]);\n","\n","    printf(\" with matrix nx %d ny %d with kernel %d\\n\", nx, ny, iKernel);\n","    size_t nBytes = nx * ny * sizeof(float);\n","\n","    // execution configuration\n","    dim3 block (blockx, blocky);\n","    dim3 grid  ((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);\n","\n","    // allocate host memory\n","    float *h_A = (float *)malloc(nBytes);\n","    float *hostRef = (float *)malloc(nBytes);\n","    float *gpuRef  = (float *)malloc(nBytes);\n","\n","    // initialize host array\n","    initialData(h_A, nx * ny);\n","\n","    // transpose at host side\n","    transposeHost(hostRef, h_A, nx, ny);\n","\n","    // allocate device memory\n","    float *d_A, *d_C;\n","    CHECK(cudaMalloc((float**)&d_A, nBytes));\n","    CHECK(cudaMalloc((float**)&d_C, nBytes));\n","\n","    // copy data from host to device\n","    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n","\n","    // warmup to avoide startup overhead\n","    double iStart = seconds();\n","    warmup<<<grid, block>>>(d_C, d_A, nx, ny);\n","    CHECK(cudaDeviceSynchronize());\n","    double iElaps = seconds() - iStart;\n","    printf(\"warmup         elapsed %f sec\\n\", iElaps);\n","    CHECK(cudaGetLastError());\n","\n","    // kernel pointer and descriptor\n","    void (*kernel)(float *, float *, int, int);\n","    const char *kernelName;\n","\n","    // set up kernel\n","    switch (iKernel)\n","    {\n","    case 0:\n","        kernel = &copyRow;\n","        kernelName = \"CopyRow       \";\n","        break;\n","\n","    case 1:\n","        kernel = &copyCol;\n","        kernelName = \"CopyCol       \";\n","        break;\n","\n","    case 2:\n","        kernel = &transposeNaiveRow;\n","        kernelName = \"NaiveRow      \";\n","        break;\n","\n","    case 3:\n","        kernel = &transposeNaiveCol;\n","        kernelName = \"NaiveCol      \";\n","        break;\n","\n","    case 4:\n","        kernel = &transposeUnroll4Row;\n","        kernelName = \"Unroll4Row    \";\n","        grid.x = (nx + block.x * 4 - 1) / (block.x * 4);\n","        break;\n","\n","    case 5:\n","        kernel = &transposeUnroll4Col;\n","        kernelName = \"Unroll4Col    \";\n","        grid.x = (nx + block.x * 4 - 1) / (block.x * 4);\n","        break;\n","\n","    case 6:\n","        kernel = &transposeDiagonalRow;\n","        kernelName = \"DiagonalRow   \";\n","        break;\n","\n","    case 7:\n","        kernel = &transposeDiagonalCol;\n","        kernelName = \"DiagonalCol   \";\n","        break;\n","    }\n","\n","    // run kernel\n","    iStart = seconds();\n","    kernel<<<grid, block>>>(d_C, d_A, nx, ny);\n","    CHECK(cudaDeviceSynchronize());\n","    iElaps = seconds() - iStart;\n","\n","    // calculate effective_bandwidth\n","    float ibnd = 2 * nx * ny * sizeof(float) / 1e9 / iElaps;\n","    printf(\"%s elapsed %f sec <<< grid (%d,%d) block (%d,%d)>>> effective \"\n","           \"bandwidth %f GB\\n\", kernelName, iElaps, grid.x, grid.y, block.x,\n","           block.y, ibnd);\n","    CHECK(cudaGetLastError());\n","\n","    // check kernel results\n","    if (iKernel > 1)\n","    {\n","        CHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));\n","        checkResult(hostRef, gpuRef, nx * ny, 1);\n","    }\n","\n","    // free host and device memory\n","    CHECK(cudaFree(d_A));\n","    CHECK(cudaFree(d_C));\n","    free(h_A);\n","    free(hostRef);\n","    free(gpuRef);\n","\n","    // reset device\n","    CHECK(cudaDeviceReset());\n","    return EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQrHMFU_KXF5"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_60  transpose.cu -o transpose\n","!./transpose 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbefiJYuKk0X"},"source":["!./transpose 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hTqFftynMeSd"},"source":["!./transpose 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiH6ehEyMffv"},"source":["!./transpose 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbVGCa8vMjZZ"},"source":["!./transpose 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wrYsvLeMpQD"},"source":["!./transpose 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A42KS45eMqNM"},"source":["!./transpose 6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHumN5kGMtOx"},"source":["!./transpose 7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOH51Do1MzW9"},"source":[""],"execution_count":null,"outputs":[]}]}