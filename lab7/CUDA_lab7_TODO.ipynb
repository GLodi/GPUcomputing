{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab7_TODO.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["F9PmBZql0ow4","7yZYCuVxpngN","iUYP4kCJhEIx","lAVvcKOX_DU0","vXUIQkZLCTcG"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyNhqXI+nbP7XbRr5fi9QE1W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g4gyOZKkHDVU"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo#scrollTo=g4gyOZKkHDVU)"]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# ✔ CUDA setup"]},{"cell_type":"code","metadata":{"id":"p9RIwaPbVQHV"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5YlC1IOTlNb"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV0CidyVeqU"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv2zAXZOu02V"},"source":["%cd /home/grossi/CUDA\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yZYCuVxpngN"},"source":["# ✔ VS code on Colab"]},{"cell_type":"code","metadata":{"id":"DKHvaMw3puK7"},"source":["# 1. Install the colab-code package...\n","!pip install colabcode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIGztaKepvqO"},"source":["# 2. Import and launch...\n","from colabcode import ColabCode\n","ColabCode()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ✔ DeviceQuery"]},{"cell_type":"code","metadata":{"id":"kW9b_Yuxi7id"},"source":["# DeviceQuery dell'attuale device\n","!nvcc /home/grossi/CUDA/lab4/deviceQuery/deviceQuery.cu -o deviceQuery\n","!deviceQuery"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAVvcKOX_DU0"},"source":["# Somma array con stream ★"]},{"cell_type":"code","metadata":{"id":"dC2HhX7YAoOd"},"source":["#@title working directory: **tabular**\n","%cd /home/grossi/CUDA/lab7/sumArrayStream\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH6TuWnB-_0M"},"source":["%%writefile /home/grossi/CUDA/lab7/sumArrayStream/sumArrayStream.cu\n","\n","#include \"../../utils/common.h\"\n","\n","/*\n"," * This example demonstrates overlapping computation and communication by\n"," * partitioning a data set and asynchronously launching the memory copies and\n"," * kernels for each subset. Launching all transfers and kernels for a given\n"," * subset in the same CUDA stream ensures that computation on the device is not\n"," * started until the necessary data has been transferred. However, because the\n"," * work of each subset is independent of all other subsets, the communication\n"," * and computation of different subsets will overlap.\n"," *\n"," * This example launches copies and kernels in breadth-first order.\n"," */\n","\n","#define NSTREAM 4\n","#define BDIM 128\n","\n","void initialData(float *ip, int size) {\n","  int i;\n","\n","  for(i = 0; i < size; i++)\n","    ip[i] = (float)(rand() & 0xFF) / 10.0f;\n","}\n","\n","void sumArraysOnHost(float *A, float *B, float *C, const int N) {\n","  for (int idx = 0; idx < N; idx++)\n","    C[idx] = A[idx] + B[idx];\n","}\n","\n","__global__ void sumArrays(float *A, float *B, float *C, const int N) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx < N)\n","      for (int i = 0; i < N; ++i)\n","        C[idx] = A[idx] + B[idx];\n","}\n","\n","void checkResult(float *hostRef, float *gpuRef, const int N) {\n","  double epsilon = 1.0E-8;\n","  bool match = 1;\n","\n","  for (int i = 0; i < N; i++) {\n","    if (abs(hostRef[i] - gpuRef[i]) > epsilon) {\n","      match = 0;\n","      printf(\"Arrays do not match!\\n\");\n","      printf(\"host %5.2f gpu %5.2f at %d\\n\", hostRef[i], gpuRef[i], i);\n","      break;\n","    }\n","  }\n","  if (match) \n","    printf(\"Arrays match.\\n\\n\");\n","}\n","\n","int main(int argc, char **argv) {\n","  printf(\"> %s Starting...\\n\", argv[0]);\n","\n","  int dev = 0;\n","  cudaDeviceProp deviceProp;\n","  CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","  printf(\"> Using Device %d: %s\\n\", dev, deviceProp.name);\n","  CHECK(cudaSetDevice(dev));\n","\n","  // check if device support hyper-q\n","  if (deviceProp.major < 3 || (deviceProp.major == 3 && deviceProp.minor < 5)) {\n","    if (deviceProp.concurrentKernels == 0) {\n","      printf(\"> GPU does not support concurrent kernel execution (SM 3.5 or higher required)\\n\");\n","      printf(\"> CUDA kernel runs will be serialized\\n\");\n","    }\n","    else {\n","      printf(\"> GPU does not support HyperQ\\n\");\n","      printf(\"> CUDA kernel runs will have limited concurrency\\n\");\n","    }\n","  }\n","\n","  printf(\"> Compute Capability %d.%d hardware with %d multi-processors\\n\",\n","          deviceProp.major, deviceProp.minor, deviceProp.multiProcessorCount);\n","\n","  // set up max connectioin\n","  char iname[] = \"CUDA_DEVICE_MAX_CONNECTIONS\";\n","  setenv (iname, \"1\", 1);\n","  char *ivalue =  getenv (iname);\n","  printf (\"> %s = %s\\n\", iname, ivalue);\n","  printf (\"> with streams = %d\\n\", NSTREAM);\n","\n","  // set up data size of vectors\n","  int nElem = 1 << 18;\n","  printf(\"> vector size = %d\\n\", nElem);\n","  size_t nBytes = nElem * sizeof(float);\n","\n","  // malloc pinned host memory for async memcpy\n","  float *h_A, *h_B, *hostRef, *gpuRef;\n","  CHECK(cudaHostAlloc((void**)&h_A, nBytes, cudaHostAllocDefault));\n","  CHECK(cudaHostAlloc((void**)&h_B, nBytes, cudaHostAllocDefault));\n","  CHECK(cudaHostAlloc((void**)&gpuRef, nBytes, cudaHostAllocDefault));\n","  CHECK(cudaHostAlloc((void**)&hostRef, nBytes, cudaHostAllocDefault));\n","\n","  // initialize data at host side\n","  initialData(h_A, nElem);\n","  initialData(h_B, nElem);\n","  memset(hostRef, 0, nBytes);\n","  memset(gpuRef,  0, nBytes);\n","\n","  // add vector at host side for result checks\n","  sumArraysOnHost(h_A, h_B, hostRef, nElem);\n","\n","  // malloc device global memory\n","  float *d_A, *d_B, *d_C;\n","  CHECK(cudaMalloc((float**)&d_A, nBytes));\n","  CHECK(cudaMalloc((float**)&d_B, nBytes));\n","  CHECK(cudaMalloc((float**)&d_C, nBytes));\n","\n","  cudaEvent_t start, stop;\n","  CHECK(cudaEventCreate(&start));\n","  CHECK(cudaEventCreate(&stop));\n","\n","  // invoke kernel at host side\n","  dim3 block (BDIM);\n","  dim3 grid  ((nElem + block.x - 1) / block.x);\n","  printf(\"> grid (%d, %d) block (%d, %d)\\n\", grid.x, grid.y, block.x, block.y);\n","\n","  // sequential operation\n","  CHECK(cudaEventRecord(start, 0));\n","  CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n","  CHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));\n","  CHECK(cudaEventRecord(stop, 0));\n","  CHECK(cudaEventSynchronize(stop));\n","  float memcpy_h2d_time;\n","  CHECK(cudaEventElapsedTime(&memcpy_h2d_time, start, stop));\n","\n","  CHECK(cudaEventRecord(start, 0));\n","  sumArrays<<<grid, block>>>(d_A, d_B, d_C, nElem);\n","  CHECK(cudaEventRecord(stop, 0));\n","  CHECK(cudaEventSynchronize(stop));\n","  float kernel_time;\n","  CHECK(cudaEventElapsedTime(&kernel_time, start, stop));\n","\n","  CHECK(cudaEventRecord(start, 0));\n","  CHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));\n","  CHECK(cudaEventRecord(stop, 0));\n","  CHECK(cudaEventSynchronize(stop));\n","  float memcpy_d2h_time;\n","  CHECK(cudaEventElapsedTime(&memcpy_d2h_time, start, stop));\n","  float itotal = kernel_time + memcpy_h2d_time + memcpy_d2h_time;\n","\n","  printf(\"\\n\");\n","  printf(\"Measured timings (throughput):\\n\");\n","  printf(\" Memcpy host to device\\t: %f ms (%f GB/s)\\n\", memcpy_h2d_time, (nBytes * 1e-6) / memcpy_h2d_time);\n","  printf(\" Memcpy device to host\\t: %f ms (%f GB/s)\\n\", memcpy_d2h_time, (nBytes * 1e-6) / memcpy_d2h_time);\n","  printf(\" Kernel\\t\\t\\t: %f ms (%f GB/s)\\n\", kernel_time, (nBytes * 2e-6) / kernel_time);\n","  printf(\" Total\\t\\t\\t: %f ms (%f GB/s)\\n\", itotal, (nBytes * 2e-6) / itotal);\n","\n","  // grid parallel operation\n","  int iElem = nElem / NSTREAM;\n","  size_t iBytes = iElem * sizeof(float);\n","  grid.x = (iElem + block.x - 1) / block.x;\n","\n","  cudaStream_t stream[NSTREAM];\n","\n","  for (int i = 0; i < NSTREAM; ++i)\n","    CHECK(cudaStreamCreate(&stream[i]));\n","\n","  CHECK(cudaEventRecord(start, 0));\n","\n","  // initiate all asynchronous transfers to the device\n","  for (int i = 0; i < NSTREAM; ++i) {\n","    int ioffset = i * iElem;\n","    CHECK(cudaMemcpyAsync(&d_A[ioffset], &h_A[ioffset], iBytes, cudaMemcpyHostToDevice, stream[i]));\n","    CHECK(cudaMemcpyAsync(&d_B[ioffset], &h_B[ioffset], iBytes, cudaMemcpyHostToDevice, stream[i]));\n","  }\n","\n","  // launch a kernel in each stream\n","  for (int i = 0; i < NSTREAM; ++i) {\n","    int ioffset = i * iElem;\n","    sumArrays<<<grid, block, 0, stream[i]>>>(&d_A[ioffset], &d_B[ioffset], &d_C[ioffset], iElem);\n","  }\n","\n","  // enqueue asynchronous transfers from the device\n","  for (int i = 0; i < NSTREAM; ++i) {\n","    int ioffset = i * iElem;\n","    CHECK(cudaMemcpyAsync(&gpuRef[ioffset], &d_C[ioffset], iBytes, cudaMemcpyDeviceToHost, stream[i]));\n","  }\n","\n","  CHECK(cudaEventRecord(stop, 0));\n","  CHECK(cudaEventSynchronize(stop));\n","  float execution_time;\n","  CHECK(cudaEventElapsedTime(&execution_time, start, stop));\n","\n","  printf(\"\\n\");\n","  printf(\"Actual results from overlapped data transfers:\\n\");\n","  printf(\" overlap with %d streams : %f ms (%f GB/s)\\n\", NSTREAM, execution_time, (nBytes * 2e-6) / execution_time );\n","  printf(\" speedup                : %f \\n\", ((itotal - execution_time) * 100.0f) / itotal);\n","\n","  // check kernel error\n","  CHECK(cudaGetLastError());\n","\n","  // check device results\n","  checkResult(hostRef, gpuRef, nElem);\n","\n","  // free device global memory\n","  CHECK(cudaFree(d_A));\n","  CHECK(cudaFree(d_B));\n","  CHECK(cudaFree(d_C));\n","\n","  // free host memory\n","  CHECK(cudaFreeHost(h_A));\n","  CHECK(cudaFreeHost(h_B));\n","  CHECK(cudaFreeHost(hostRef));\n","  CHECK(cudaFreeHost(gpuRef));\n","\n","  // destroy events\n","  CHECK(cudaEventDestroy(start));\n","  CHECK(cudaEventDestroy(stop));\n","\n","  // destroy streams\n","  for (int i = 0; i < NSTREAM; ++i)\n","    CHECK(cudaStreamDestroy(stream[i]));\n","\n","  CHECK(cudaDeviceReset());\n","  return(0);\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7G91KROXBScK"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 sumArrayStream.cu  -o sumArrayStream\n","!sumArrayStream"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# Tabular ★\n"]},{"cell_type":"code","metadata":{"id":"lMElD9hZCUcg"},"source":["#@title working directory: **tabular**\n","%cd /home/grossi/CUDA/lab7/tabular\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%writefile /home/grossi/CUDA/lab7/tabular/tabular.cu\n","\n","#include <stdio.h>\n","#include \"../../utils/common.h\"\n","\n","#define PI 3.141592f\n","\n","/*\n"," * Kernel: tabular function\n"," */\n","__global__ void tabular(float *a, int n) {\n","\tint i = threadIdx.x + blockIdx.x * blockDim.x;\n","\tif (i < n) {\n","\t\tfloat x = PI * (float)i / (float)n;\n","\t\tfloat s = sinf(x);\n","\t\tfloat c = cosf(x);\n","\t\ta[i] = sqrtf(abs(s * s - c * c));\n","\t}\n","}\n","\n","/*\n"," * Kernel: tabular function using streams\n"," */\n","__global__ void tabular_streams(float *a, int n, int offset) {\n","\tint i = offset + threadIdx.x + blockIdx.x * blockDim.x;\n","  if (i < n) {\n","    float x = PI * (float)i / (float)n;\n","    float s = sinf(x);\n","    float c = cosf(x);\n","    a[i] = sqrtf(abs(s * s - c * c));\n","  }\n","}\n","\n","/*\n"," * Error measure\n"," */\n","float maxError(float *a, int n) {\n","\tfloat maxE = 0;\n","\tfor (int i = 0; i < n; i++) {\n","\t\tfloat error = fabs(a[i] - 1.0f);\n","\t\tif (error > maxE)\n","\t\t\tmaxE = error;\n","\t}\n","\treturn maxE;\n","}\n","\n","/*\n"," * Main: tabular function\n"," */\n","int main(void) {\n","\t\n","  // main params\n","  uint MB = 1024*1024; \n","  uint n = 256*MB;\n","\tint blockSize = 256;\n","\tint nStreams = 8;\n","\n","\tint streamSize = n / nStreams;\n","\tint streamBytes = streamSize * sizeof(float);\n","\tint bytes = n * sizeof(float);\n","\n","\tint devId = 0;\n","\tcudaDeviceProp prop;\n","\tCHECK(cudaGetDeviceProperties(&prop, devId));\n","\tprintf(\"Device : %s\\n\\n\", prop.name);\n","\tCHECK(cudaSetDevice(devId));\n","  printf(\"Array size   : %d\\n\", n);\n","  printf(\"StreamSize   : %d\\n\", streamSize);\n","  printf(\"Memory bytes : %d (MB)\\n\", bytes/MB);\n","  printf(\"streamBytes  : %d (MB)\\n\", streamBytes/MB);\n","\n","\t// allocate pinned host memory and device memory\n","\tfloat *a, *d_a;\n","\tCHECK(cudaMallocHost((void**) &a, bytes));      // host pinned\n","\tCHECK(cudaMalloc((void**) &d_a, bytes));        // device\n","\n","\tfloat ms; // elapsed time in milliseconds\n","\n","\t// create events and streams\n","\tcudaEvent_t startEvent, stopEvent, dummyEvent;\n","\tcudaStream_t stream[nStreams];\n","\tCHECK(cudaEventCreate(&startEvent));\n","\tCHECK(cudaEventCreate(&stopEvent));\n","\tCHECK(cudaEventCreate(&dummyEvent));\n","\tfor (int i = 0; i < nStreams; ++i)\n","\t\tCHECK(cudaStreamCreate(&stream[i]));\n","\n","\t// baseline case - sequential transfer and execute\n","\tmemset(a, 0, bytes);\n","\tCHECK(cudaEventRecord(startEvent, 0));\n","\tCHECK(cudaMemcpy(d_a, a, bytes, cudaMemcpyHostToDevice));\n","\ttabular<<<n / blockSize, blockSize>>>(d_a, n);\n","\tCHECK(cudaMemcpy(a, d_a, bytes, cudaMemcpyDeviceToHost));\n","\tCHECK(cudaEventRecord(stopEvent, 0));\n","\tCHECK(cudaEventSynchronize(stopEvent));\n","\tCHECK(cudaEventElapsedTime(&ms, startEvent, stopEvent));\n","\tprintf(\"\\nTime for sequential transfer and execute (ms): %f\\n\", ms);\n","\tprintf(\"  max error: %e\\n\", maxError(a, n));\n","\n","\t// asynchronous version 1: loop over {copy, kernel, copy}\n","\tmemset(a, 0, bytes);\n","\tCHECK(cudaEventRecord(startEvent, 0));\n","\tfor (int i = 0; i < nStreams; ++i) {\n","\t\tint offset = i * streamSize;\n","\t\tCHECK(cudaMemcpyAsync(&d_a[offset], &a[offset], streamBytes,cudaMemcpyHostToDevice, stream[i]));\n","\t\ttabular_streams<<<streamSize / blockSize, blockSize, 0, stream[i]>>>(d_a,n,offset);\n","\t\tCHECK(cudaMemcpyAsync(&a[offset], &d_a[offset], streamBytes, cudaMemcpyDeviceToHost, stream[i]));\n","\t}\n","\tCHECK(cudaEventRecord(stopEvent, 0));\n","\tCHECK(cudaEventSynchronize(stopEvent));\n","\tCHECK(cudaEventElapsedTime(&ms, startEvent, stopEvent));\n","\tprintf(\"\\nTime for asynchronous V1 transfer and execute (ms): %f\\n\", ms);\n","\tprintf(\"  max error: %e\\n\", maxError(a, n));\n","\n","\t// asynchronous version 2:\n","\t// loop over copy, loop over kernel, loop over copy\n","\tmemset(a, 0, bytes);\n","\tCHECK(cudaEventRecord(startEvent, 0));\n","\tfor (int i = 0; i < nStreams; ++i) {\n","\t\tint offset = i * streamSize;\n","\t\tCHECK(cudaMemcpyAsync(&d_a[offset], &a[offset], streamBytes,cudaMemcpyHostToDevice, stream[i]));\n","\t}\n","\tfor (int i = 0; i < nStreams; ++i) {\n","\t\tint offset = i * streamSize;\n","\t\ttabular_streams<<<streamSize / blockSize, blockSize, 0, stream[i]>>>(d_a,n,offset);\n","\t}\n","\tfor (int i = 0; i < nStreams; ++i) {\n","\t\tint offset = i * streamSize;\n","\t\tCHECK(cudaMemcpyAsync(&a[offset], &d_a[offset], streamBytes,cudaMemcpyDeviceToHost, stream[i]));\n","\t}\n","\tCHECK(cudaEventRecord(stopEvent, 0));\n","\tCHECK(cudaEventSynchronize(stopEvent));\n","\tCHECK(cudaEventElapsedTime(&ms, startEvent, stopEvent));\n","\tprintf(\"\\nTime for asynchronous V2 transfer and execute (ms): %f\\n\", ms);\n","\tprintf(\"  max error: %e\\n\", maxError(a, n));\n","\n","\t// cleanup\n","\tCHECK(cudaEventDestroy(startEvent));\n","\tCHECK(cudaEventDestroy(stopEvent));\n","\tCHECK(cudaEventDestroy(dummyEvent));\n","\tfor (int i = 0; i < nStreams; ++i)\n","\t\tCHECK(cudaStreamDestroy(stream[i]));\n","\tcudaFree(d_a);\n","\tcudaFreeHost(a);\n","\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 tabular.cu  -o tabular\n","!tabular"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfR471rze2p-"},"source":["# profilazione (senza unified memory - dà errore)\n","\n","!nvprof ./tabular"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# MQDB con stream ★"]},{"cell_type":"code","metadata":{"id":"-_tGfHL2aRiB"},"source":["#@title working directory: **MQDB_stream**\n","%cd /home/grossi/CUDA/lab7/MQDB_stream/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%writefile /home/grossi/CUDA/lab7/MQDB_stream/MQDB_stream_Unified_TODO.cu\n","\n","\n","#include \"../../utils/MQDB/mqdb.h\"\n","#include \"../../utils/common.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","#define TEST_CPU 0\n","\n","/*\n"," * Kernel for standard (naive) matrix product\n"," */\n","__global__ void matProdKernel(mqdb *A, mqdb *B, mqdb *C, int n) {\n","\t// row & col indexes\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < n) && (col < n)) {\n","\t\tfloat val = 0;\n","\t\tfor (int k = 0; k < n; k++)\n","\t\t\tval += A->elem[row * n + k] * B->elem[k * n + col];\n","\t\tC->elem[row * n + col] = val;\n","\t}\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb\n"," */\n","__global__ void mqdbBlockProd(mqdb *A, mqdb *B, mqdb *C, uint sdim, uint d, uint n) {\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// jump to the right block sub-matrix\n","\tuint  offset = (n+1)*sdim;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < d) && (col < d)) {\n","\t\tfloat val = 0;\n","\t\tfor (int k = 0; k < d; k++)\n","\t\t\tval += A->elem[row * n + k + offset] * B->elem[k * n + col + offset];\n","\t\tC->elem[row * n + col + offset] = val;\n","\t}\n","}\n","\n","\n","/*\n"," * Test on MQDB kernels using Unified Memory\n"," */\n","void testKernelsMQDB_unified(uint n, uint k, cudaEvent_t start, cudaEvent_t stop) {\n","\n","\t// TODO\n","\t\n","\t/***********************************************************/\n","\t/*                    CPU MQDB product                     */\n","\t/***********************************************************/\n","\t\n","  printf(\"CPU MQDB product...\\n\");\n","\tdouble CPUtime = 0.0;\n","\n","  #if TEST_CPU\n","    double startTm = seconds();\n","\t  mqdbProd(A,B,C);\n","\t  CPUtime = seconds() - startTm;\n","  #endif\n","\n","\tprintf(\"   CPU elapsed time: %.5f (sec)\\n\\n\", CPUtime);\n","\n","\t/***********************************************************/\n","\t/*                     GPU mat product                     */\n","\t/***********************************************************/\n","\t\n","  printf(\"Kernel (naive) mat product...\\n\");\n","\n","  // TODO - using matProdKernel\n","\n","\n","\t/***********************************************************/\n","\t/*                     GPU MQDB product                    */\n","\t/***********************************************************/\n","\t\n","  printf(\"Kernel MQDB product...\\n\");\n","\t\n","  // TODO - using mqdbBlockProd\n","\n","  /***********************************************************/\n","\t/*             GPU MQDB product using streams              */\n","\t/***********************************************************/\n","\t\n","  printf(\"GPU MQDB product using streams...\\n\");\n","\n","  // TODO - using mqdbBlockProd + streams\n","\n","}\n","\n","/*\n"," * main function\n"," */\n","int main(int argc, char *argv[]) {\n","  \n","  // set up device\n","\tint dev = 0;\n","\tcudaDeviceProp deviceProp;\n","\tCHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","\tprintf(\"%s starting mqdb product at \", argv[0]);\n","\tprintf(\"device %d: %s\\n\", dev, deviceProp.name);\n","\tCHECK(cudaSetDevice(dev));\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\tuint n = 16*1024;         // matrix size\n","\tuint min_k = 20;       // max num of blocks\n","\tuint max_k = 30;       // max num of blocks\n","\n","\t// multiple tests for k = # diag blocks\n","\tfor (uint k = min_k; k <= max_k; k+=5) {\n","\t\tprintf(\"\\n*****   k = %d --- (avg block size = %f)\\n\",k,(float)n/k);\n","\t\ttestKernelsMQDB_unified(n, k, start, stop);\n","\t}\n","\n","  cudaEventDestroy(start);\n","\tcudaEventDestroy(stop);\n","\treturn 0;\n","}\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_60  MQDB_stream_Unified.cu ../../utils/MQDB/mqdb.cpp -o MQDB_stream\n","!./MQDB_stream"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6fYYbj397SdK"},"source":["%%writefile /home/grossi/CUDA/lab7/MQDB_stream/MQDB_stream_manual_TODO.cu\n","\n","\n","#include \"../../utils/MQDB/mqdb.h\"\n","#include \"../../utils/common.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","#define TEST_CPU 0\n","\n","/*\n"," * Kernel for standard (naive) matrix product\n"," */\n","__global__ void matProdKernel(mqdb A, mqdb B, mqdb C, int n) {\n","\t// row & col indexes\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < n) && (col < n)) {\n","\t\tfloat val = 0;\n","\t\tfor (int k = 0; k < n; k++)\n","\t\t\tval += A.elem[row * n + k] * B.elem[k * n + col];\n","\t\tC.elem[row * n + col] = val;\n","\t}\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb\n"," */\n","__global__ void mqdbBlockProd(mqdb A, mqdb B, mqdb C, uint sdim, uint d, uint n) {\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// jump to the right block sub-matrix\n","\tuint  offset = (n+1)*sdim;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < d) && (col < d)) {\n","\t\tfloat val = 0;\n","\t\tfor (int k = 0; k < d; k++)\n","\t\t\tval += A.elem[row * n + k + offset] * B.elem[k * n + col + offset];\n","\t\tC.elem[row * n + col + offset] = val;\n","\t}\n","}\n","\n","/*\n"," * Test on MQDB kernels using manual async memory\n"," */\n","void testKernelsMQDB_manual_mem(uint n, uint k, cudaEvent_t start, cudaEvent_t stop) {\n","\n","  // TODO\n","\t\n","\t/***********************************************************/\n","\t/*                    CPU MQDB product                     */\n","\t/***********************************************************/\n","\t\n","  printf(\"CPU MQDB product...\\n\");\n","\tdouble CPUtime = 0.0;\n","\n","  #if TEST_CPU\n","    double startTm = seconds();\n","\t  mqdbProd(A,B,C);\n","\t  CPUtime = seconds() - startTm;\n","  #endif\n","\n","\tprintf(\"   CPU elapsed time: %.5f (sec)\\n\\n\", CPUtime);\n","\n","\t/***********************************************************/\n","\t/*                     GPU mat product                     */\n","\t/***********************************************************/\n","\t\n","  printf(\"Kernel (naive) mat product...\\n\");\n","\n","  // TODO - using matProdKernel\n","\n","\n","\t/***********************************************************/\n","\t/*                     GPU MQDB product                    */\n","\t/***********************************************************/\n","\t\n","  printf(\"Kernel MQDB product...\\n\");\n","\t\n","  // TODO - using mqdbBlockProd\n","\n","  /***********************************************************/\n","\t/*             GPU MQDB product using streams              */\n","\t/***********************************************************/\n","\t\n","  printf(\"GPU MQDB product using streams...\\n\");\n","\n","  // TODO - using mqdbBlockProd + streams\n","} \n","\n","/*\n"," * main function\n"," */\n","int main(int argc, char *argv[]) {\n","  \n","  // set up device\n","\tint dev = 0;\n","\tcudaDeviceProp deviceProp;\n","\tCHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","\tprintf(\"%s starting mqdb product at \", argv[0]);\n","\tprintf(\"device %d: %s\\n\", dev, deviceProp.name);\n","\tCHECK(cudaSetDevice(dev));\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\tuint n = 16*1024;         // matrix size\n","\tuint min_k = 20;       // max num of blocks\n","\tuint max_k = 30;       // max num of blocks\n","\n","\t// multiple tests for k = # diag blocks\n","\tfor (uint k = min_k; k <= max_k; k+=5) {\n","\t\tprintf(\"\\n*****   k = %d --- (avg block size = %f)\\n\",k,(float)n/k);\n","\t\ttestKernelsMQDB_manual_mem(n, k, start, stop);\n","\t}\n","\n","  cudaEventDestroy(start);\n","\tcudaEventDestroy(stop);\n","\treturn 0;\n","}\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmMmj5KDnteq"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_60  MQDB_stream_manual.cu ../../utils/MQDB/mqdb.cpp -o MQDB_streamM\n","!./MQDB_streamM"],"execution_count":null,"outputs":[]}]}